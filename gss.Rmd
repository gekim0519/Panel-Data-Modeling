---
title: "Panel Data Modeling"
author: "Sara Kim"
date: "5/30/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(purrr)
library(Amelia)
```

```{r, message=FALSE, warning=FALSE}
gss_all_original = readr::read_csv('./data/gss-all-panels-06-14.csv')

# Instead of removing ".d", ".i", ".n" I will alter them to NAs.
gss_all = readr::read_csv('./data/gss-all-panels-06-14.csv', na = c(".d", ".i", ".n")) %>%
  janitor::remove_empty_cols()
```

So in `gss_all`, I changed all ".d", ".i", ".n" to NAs and removed columns that were all NAs.

To go further, I will remove sparse columns as there seems to be many. I will set the preliminary threshold as features having more than 90% as missings (values: ".d", ".i", ".n").

I won't remove variables regarding confidence in institution.

```{r}
removed = c()
dont_remove = grep("^con", names(gss_all), value=TRUE)

for(col in colnames(gss_all)){
  na_percent = gss_all[[col]] %>% is.na() %>% mean()
  if(na_percent > 0.9) {
    if(!(col %in% dont_remove)){
    removed = c(removed, col)
    gss_all = gss_all %>% select(-col)
    }
  }
}
```
I see that we now have removed 999 variables and there are 522 variables in `gss_all`.

#### todo check removed variables

Notice that some of the `con-` variables are very sparse for instance, `conbiz` has 99.8% missings.

```{r}
gss_all %>% select(conbiz) %>% is.na() %>% mean()
```

changing orders in levels of `tvhours` so that they will be in numerical order.

```{r}
gss_all$tvhours = gss_all$tvhours %>% factor(levels = c("0",  "1", "2", "3", "4",  "5",  "6",  "7",  "8",  "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "23", "24"))
```

## Project Idea 

When people express less confidence in a certain institution, do we see them engaging with that institution less too?  Confidence in institutions has dropped dramatically, with implications for civil society, social capital and public trust.  Using two-way fixed effects models (that control for stable, time-invariant characteristics of individuals), I find some evidence that when people's confidence in certain institutions changes, so too does their participation and commitment to those institutions.  This is consistent with a theory that people’s opinions and actions share some common basis and are not “uncoupled” from each other.  This appears true for confidence in TV, religion, business and unions, but not so for confidence in the press or education.  Using random intercept cross-lagged SEMs, we can also test whether the relationship is bi-directional or only goes one-way.    

Let's first explore the relationship between confidence in TV (`contv`) and their daily TV watching habits (`tvhours`).

The variables we are going to focus is these two:

`CONTV`: I am going to name some institutions in this country. As far as the people running these institutions are concerned, would you say you have a great deal of confidence, only some confidence, or hardly any confidence at all in them? 

`TVHOURS`: On the average day, about how many hours do you personally watch television?

## Data Exploration

First of all, let's look at the size of our data.

```{r}
dim(gss_all)
unique(gss_all$idnum) %>% length()
```

There are data from 6067 participants.

### Frequency table

```{r}
gss_all$tvhours %>% 
  table() %>%
  as.data.frame(col.names = values) %>%
  rename(., values = .) %>%
  mutate(Percent = Freq/sum(Freq)) %>%
  knitr::kable()


gss_all$contv %>% 
  table() %>%
  as.data.frame(col.names = values) %>%
  rename(., values = .) %>%
  mutate(Percent = Freq/sum(Freq)) %>%
  knitr::kable()

```

I made Frequency tables for the two variables. Let's see summary statistics for `tvhours` by considering `tvhours` as a numeric variable.

```{r}
gss_all$tvhours %>% 
  as.numeric() %>%
  Hmisc::describe()
```

I will plot the two variables for each `panelwave` and see if the distribution changes depending on the wave.

```{r}
 gss_all %>%
  ggplot(aes(x=contv)) +
  geom_bar(stat="count") + 
  facet_grid(. ~ panelwave)

 gss_all %>%
  ggplot(aes(x=tvhours)) +
  geom_bar(stat="count") + 
  facet_grid(. ~ panelwave)
```

Seems like there is no apparent difference in the trends among the three panels.

```{r}
set.seed(100) 

gss_all %>%
  filter(idnum %in% (gss_all$idnum %>% sample(1000))) %>%
  mutate(idnum = factor(idnum)) %>%
  ggplot(aes(x = panelwave, y = tvhours, group = idnum, color = idnum)) +
  geom_point() + geom_line(alpha = 0.5) + theme(legend.position="none")
```

Just sampled 1000 participants to see if there is a pattern. 

### Correlation

Below is a correlation matrix between `contv` and `tvhours` for the first wave. I removed non-numeric values and altered the variables to be numeric to see the relationship.

```{r}
# just panel 1

gss_numeric = map_df(gss_all, as.numeric) 

gss_numeric_p1 = gss_numeric %>%
  filter(panelwave == 1)

# cor matrix between contv and tvhours
gss_numeric_p1  %>%
  select(tvhours, contv) %>%
  cor(use="complete.obs")

panel1_cor = cor(gss_numeric_p1, use="p")

contv_cor = panel1_cor  %>%
  as.data.frame() %>%
  select(contv) %>%
  rownames_to_column('var') %>% 
  filter(abs(contv) > 0.2)

# negatively corr check
# check top ten? five?
# try ten% 
# put in the y var in amelia

contv_cor
```
Above is a pearson correlation coefficient with `contv` with all the other variables. I have filtered out those that are above 0.2 or below -0.2.

Let's get top 10 vars correlated to `tvhours` and `contv` with `correlate()` from `corrr` package.

#### look correlation on whole dataset? Or just wave 1?

```{r}
library(corrr)

# function for finding top n correlated variables 
corr_var = function(df, col, n = 10){
  
  col = enquo(col)
  
  top_n = df  %>% correlate() %>% select(rowname, !! col )  %>% top_n(n, abs(!!col))
  top_n %>% arrange(desc(abs(!!col)))
  }

# top 10 correlated vars to contv
cor_contv = corr_var(gss_numeric_p1, contv, 10)
corr_var(gss_numeric, contv, 10)
cor_tvhours = corr_var(gss_numeric_p1, tvhours, 10)
```

To do analysis, I will impute not just on the first panel but on the whole dataset.

I tried to get imputed factor variables but I am getting errors.
I will impute numeric variables.

```{r}
imputed_contv = gss_numeric %>%
  select(idnum, panelwave, contv, cor_contv$rowname) %>%
  amelia(idvars = "idnum", ts = "panelwave", ords = c("contv", "conpress", "tvhours", "conmedic", "confinan", "coneduc", "fejobaff", "conlabor", "wordsum", "conlegis", "conjudge"))

imputed_contv = bind_rows(unclass(imputed_contv$imputations), .id = "m") %>%
  group_by(m) %>%
  nest()
```
There are still lot of NAs because some rows in waves 2 and three are completely missing.
I will try to impute a wide formatted data.

```{r}
# change the data to a wide format
long_to_wide = function(df){
  df %>% 
  gather(key, value, -idnum, -panelwave) %>%  
     unite(new.col, c(key, panelwave)) %>%   
     spread(new.col, value) 
}

contv_wide = list()
for(i in c(1:5)){
  contv_wide[[i]] = imputed_contv[[2]][[i]] %>%
    long_to_wide()
}

names(contv_wide[[1]])[-1]

# impute wide data
imputed_wide = contv_wide[[1]]%>%
  amelia(idvars = "idnum", ords = names(contv_wide[[1]])[-1]) 

imputed_wide = bind_rows(unclass(imputed_wide$imputations), .id = "m") %>%
  group_by(m) %>%
  nest()

# rows to remove
imputed_wide[[2]][[1]][!complete.cases(imputed_wide[[2]][[1]]), ]

imputed = imputed_wide[[2]][[1]]

imputed_contv[[2]][[1]] %>% names()
        
wide_to_long = function(df){
  df %>% 
    gather(name, value, -idnum) %>%
    separate(name, into=c("name", "id"), sep= -2) %>%
    spread(key=c(name), value) %>%
    separate(id, into = c("remove", "panelwave"), sep = -1) %>%
    select(-remove)
}
```


## Modeling

Run fixed effects models.  Run “within and between” models.  Trying multinomial fixed effects models.

Fixed effects models from the survival package.

```{r}
library(survival)

fe_contv = 
  imputed %>%
  wide_to_long() %>%
  mutate(panelwave = as.numeric(panelwave)) %>%
  clogit(tvhours ~ contv + panelwave + conpress + conmedic + confinan + conlegis + coneduc + fejobaff + conlabor + wordsum + conjudge + strata(idnum), data = ., method = "efron")


summary(fe_contv)
```

With imputed data that has na rows
```{r}
library(broom)
models_imputations <- imputed_contv  %>%
  mutate(model = data %>% map(~ clogit(tvhours ~ contv + panelwave + conpress + conmedic + confinan + conlegis + coneduc + fejobaff + conlabor + wordsum + conjudge + strata(idnum), data = ., method = "efron")),
         tidied = model %>% map(~ tidy(., conf.int = TRUE)),
         glance = model %>% map(~ glance(.)))
```

```{r}
models_imputations$tidied[[1]]
```

